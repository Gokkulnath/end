{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 5 - TorchText",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gokkulnath/end/blob/main/Session_5_TorchText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKb3KfJgzpun"
      },
      "source": [
        "from torchtext.datasets import AG_NEWS, YelpReviewFull, YelpReviewPolarity"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pXFnhhMzx4R",
        "outputId": "2a5f915c-56f0-44c2-bc99-44740b9c9c5c"
      },
      "source": [
        "help(YelpReviewFull)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function YelpReviewFull in module torchtext.datasets.yelpreviewfull:\n",
            "\n",
            "YelpReviewFull(root='.data', split=('train', 'test'))\n",
            "    YelpReviewFull dataset\n",
            "    \n",
            "    Separately returns the train/test split\n",
            "    \n",
            "    Number of lines per split:\n",
            "        train: 650000\n",
            "    \n",
            "        test: 50000\n",
            "    \n",
            "    \n",
            "    Number of classes\n",
            "        5\n",
            "    \n",
            "    \n",
            "    Args:\n",
            "        root: Directory where the datasets are saved.\n",
            "            Default: .data\n",
            "        split: split or splits to be returned. Can be a string or tuple of strings.\n",
            "            Default: ('train', 'test')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ryUc8O_Oz3B",
        "outputId": "0b16dbd2-a86e-4c43-9cb5-4d0207fa6778"
      },
      "source": [
        "1/5 *1.5"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.30000000000000004"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7LwnrU-0cMI",
        "outputId": "f8203c15-59d8-4fdc-ccc0-8f12e94d21c3"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_iter = YelpReviewFull(split = 'train')\n",
        "test_iter = YelpReviewFull(split = 'test')\n",
        "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False)\n",
        "next(iter(dataloader))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([5, 2, 4, 4, 1, 5, 5, 1]),\n",
              " (\"dr. goldberg offers everything i look for in a general practitioner.  he's nice and easy to talk to without being patronizing; he's always on time in seeing his patients; he's affiliated with a top-notch hospital (nyu) which my parents have explained to me is very important in case something happens and you need surgery; and you can get referrals to see specialists without having to see him first.  really, what more do you need?  i'm sitting here trying to think of any complaints i have about him, but i'm really drawing a blank.\",\n",
              "  \"Unfortunately, the frustration of being Dr. Goldberg's patient is a repeat of the experience I've had with so many other doctors in NYC -- good doctor, terrible staff.  It seems that his staff simply never answers the phone.  It usually takes 2 hours of repeated calling to get an answer.  Who has time for that or wants to deal with it?  I have run into this problem with many other doctors and I just don't get it.  You have office workers, you have patients with medical needs, why isn't anyone answering the phone?  It's incomprehensible and not work the aggravation.  It's with regret that I feel that I have to give Dr. Goldberg 2 stars.\",\n",
              "  \"Been going to Dr. Goldberg for over 10 years. I think I was one of his 1st patients when he started at MHMG. He's been great over the years and is really all about the big picture. It is because of him, not my now former gyn Dr. Markoff, that I found out I have fibroids. He explores all options with you and is very patient and understanding. He doesn't judge and asks all the right questions. Very thorough and wants to be kept in the loop on every aspect of your medical health and your life.\",\n",
              "  'Got a letter in the mail last week that said Dr. Goldberg is moving to Arizona to take a new position there in June.  He will be missed very much.  \\\\n\\\\nI think finding a new doctor in NYC that you actually like might almost be as awful as trying to find a date!',\n",
              "  \"I don't know what Dr. Goldberg was like before  moving to Arizona, but let me tell you, STAY AWAY from this doctor and this office. I was going to Dr. Johnson before he left and Goldberg took over when Johnson left. He is not a caring doctor. He is only interested in the co-pay and having you come in for medication refills every month. He will not give refills and could less about patients's financial situations. Trying to get your 90 days mail away pharmacy prescriptions through this guy is a joke. And to make matters even worse, his office staff is incompetent. 90% of the time when you call the office, they'll put you through to a voice mail, that NO ONE ever answers or returns your call. Both my adult children and husband have decided to leave this practice after experiencing such frustration. The entire office has an attitude like they are doing you a favor. Give me a break! Stay away from this doc and the practice. You deserve better and they will not be there when you really need them. I have never felt compelled to write a bad review about anyone until I met this pathetic excuse for a doctor who is all about the money.\",\n",
              "  \"Top notch doctor in a top notch practice. Can't say I am surprised when I was referred to him by another doctor who I think is wonderful and because he went to one of the best medical schools in the country. \\\\nIt is really easy to get an appointment. There is minimal wait to be seen and his bedside manner is great.\",\n",
              "  'Dr. Eric Goldberg is a fantastic doctor who has correctly diagnosed every issue that my wife and I have had. Unlike many of my past doctors, Dr. Goldberg is very accessible and we have been able to schedule appointments with him and his staff very quickly. We are happy to have him in the neighborhood and look forward to being his patients for many years to come.',\n",
              "  \"I'm writing this review to give you a heads up before you see this Doctor. The office staff and administration are very unprofessional. I left a message with multiple people regarding my bill, and no one ever called me back. I had to hound them to get an answer about my bill. \\\\n\\\\nSecond, and most important, make sure your insurance is going to cover Dr. Goldberg's visits and blood work. He recommended to me that I get a physical, and he knew I was a student because I told him. I got the physical done. Later, I found out my health insurance doesn't pay for preventative visits. I received an $800.00 bill for the blood work. I can't pay for my bill because I'm a student and don't have any cash flow at this current time. I can't believe the Doctor wouldn't give me a heads up to make sure my insurance would cover work that wasn't necessary and was strictly preventative. The office can't do anything to help me cover the bill. In addition, the office staff said the onus is on me to make sure my insurance covers visits. Frustrating situation!\")]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq-IuEKY2GQR"
      },
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "  for _, text in data_iter:\n",
        "    yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Cp7Qbw6xS1"
      },
      "source": [
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OKrep6I7JqF",
        "outputId": "bc372985-d361-4d1e-afc0-1f2e0d952353"
      },
      "source": [
        "vocab(['top', 'notch', 'doctor' ,'in' ,'a' ,'top' ,'notch', 'practice'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[294, 1699, 1549, 13, 6, 294, 1699, 2490]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQVgPe4P7Xef",
        "outputId": "c6f3ab25-8c44-42bf-9812-665bbfd740dd"
      },
      "source": [
        "vocab[\"<unk>\"]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK1sxfsM7doh"
      },
      "source": [
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: int(x) - 1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iiJdwCO79Yx",
        "outputId": "a98b0c1d-b03c-4a37-be2b-06680a9c34df"
      },
      "source": [
        "text_pipeline(\"Top notch doctor in a top notch practice\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[294, 1699, 1549, 13, 6, 294, 1699, 2490]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xArz2o1P8MKG"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def collate_fn(batch):\n",
        "  src_batch, tgt_batch = [], []\n",
        "  for src_batch, tgt_batch in batch:\n",
        "    src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip('\\n')))\n",
        "    tgt_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip('\\n')))\n",
        "  src_batch = pad_sequences(src_batch, padding_value=PAD_IDX)\n",
        "  tgt_batch = pad_sequences(tgt_batch, padding_value=PAD_IDX)\n",
        "  return src_batch, tgt_batch"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSeLl_Sh-6ON"
      },
      "source": [
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for (_label, _text) in batch:\n",
        "         label_list.append(label_pipeline(_label))\n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)    "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRDpOkXiAqyo"
      },
      "source": [
        "train_iter = YelpReviewFull(split='train')\n",
        "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-IOBmF7A1N-"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class TextClassificationModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKuQGv-xBIC1"
      },
      "source": [
        "1: World, 2: Sports, 3 Business, 4 Sci/Tech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW1rS0OYBGhR"
      },
      "source": [
        "num_class = len(set([label for (label, text) in train_iter]))\n",
        "vocab_size = len(vocab)\n",
        "emsize = 64\n",
        "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtVCypgvBQfM"
      },
      "source": [
        "import time\n",
        "\n",
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        predited_label = model(text, offsets)\n",
        "        loss = criterion(predited_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1) # disuccees\n",
        "        optimizer.step()\n",
        "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "                  '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "                                              total_acc/total_count))\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predited_label = model(text, offsets)\n",
        "            loss = criterion(predited_label, label)\n",
        "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc/total_count"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV7lPedpBfpS",
        "outputId": "24d286c0-4e1c-470b-b384-8a982fc0dff0"
      },
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "# Hyperparameters\n",
        "EPOCHS = 10 # epoch\n",
        "LR = 5  # learning rate\n",
        "BATCH_SIZE = 64 # batch size for training\n",
        "  \n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "train_iter, test_iter = YelpReviewFull()\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "split_train_, split_valid_ = \\\n",
        "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
        "\n",
        "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
        "                             shuffle=True, collate_fn=collate_batch)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_val))\n",
        "    print('-' * 59)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 9649 batches | accuracy    0.388\n",
            "| epoch   1 |  1000/ 9649 batches | accuracy    0.486\n",
            "| epoch   1 |  1500/ 9649 batches | accuracy    0.514\n",
            "| epoch   1 |  2000/ 9649 batches | accuracy    0.525\n",
            "| epoch   1 |  2500/ 9649 batches | accuracy    0.539\n",
            "| epoch   1 |  3000/ 9649 batches | accuracy    0.540\n",
            "| epoch   1 |  3500/ 9649 batches | accuracy    0.549\n",
            "| epoch   1 |  4000/ 9649 batches | accuracy    0.555\n",
            "| epoch   1 |  4500/ 9649 batches | accuracy    0.556\n",
            "| epoch   1 |  5000/ 9649 batches | accuracy    0.558\n",
            "| epoch   1 |  5500/ 9649 batches | accuracy    0.561\n",
            "| epoch   1 |  6000/ 9649 batches | accuracy    0.563\n",
            "| epoch   1 |  6500/ 9649 batches | accuracy    0.564\n",
            "| epoch   1 |  7000/ 9649 batches | accuracy    0.563\n",
            "| epoch   1 |  7500/ 9649 batches | accuracy    0.561\n",
            "| epoch   1 |  8000/ 9649 batches | accuracy    0.567\n",
            "| epoch   1 |  8500/ 9649 batches | accuracy    0.560\n",
            "| epoch   1 |  9000/ 9649 batches | accuracy    0.569\n",
            "| epoch   1 |  9500/ 9649 batches | accuracy    0.572\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time: 133.54s | valid accuracy    0.551 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 9649 batches | accuracy    0.574\n",
            "| epoch   2 |  1000/ 9649 batches | accuracy    0.574\n",
            "| epoch   2 |  1500/ 9649 batches | accuracy    0.572\n",
            "| epoch   2 |  2000/ 9649 batches | accuracy    0.575\n",
            "| epoch   2 |  2500/ 9649 batches | accuracy    0.579\n",
            "| epoch   2 |  3000/ 9649 batches | accuracy    0.578\n",
            "| epoch   2 |  3500/ 9649 batches | accuracy    0.576\n",
            "| epoch   2 |  4000/ 9649 batches | accuracy    0.582\n",
            "| epoch   2 |  4500/ 9649 batches | accuracy    0.580\n",
            "| epoch   2 |  5000/ 9649 batches | accuracy    0.575\n",
            "| epoch   2 |  5500/ 9649 batches | accuracy    0.580\n",
            "| epoch   2 |  6000/ 9649 batches | accuracy    0.577\n",
            "| epoch   2 |  6500/ 9649 batches | accuracy    0.574\n",
            "| epoch   2 |  7000/ 9649 batches | accuracy    0.579\n",
            "| epoch   2 |  7500/ 9649 batches | accuracy    0.583\n",
            "| epoch   2 |  8000/ 9649 batches | accuracy    0.579\n",
            "| epoch   2 |  8500/ 9649 batches | accuracy    0.587\n",
            "| epoch   2 |  9000/ 9649 batches | accuracy    0.582\n",
            "| epoch   2 |  9500/ 9649 batches | accuracy    0.580\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time: 125.04s | valid accuracy    0.566 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 9649 batches | accuracy    0.586\n",
            "| epoch   3 |  1000/ 9649 batches | accuracy    0.586\n",
            "| epoch   3 |  1500/ 9649 batches | accuracy    0.582\n",
            "| epoch   3 |  2000/ 9649 batches | accuracy    0.583\n",
            "| epoch   3 |  2500/ 9649 batches | accuracy    0.587\n",
            "| epoch   3 |  3000/ 9649 batches | accuracy    0.580\n",
            "| epoch   3 |  3500/ 9649 batches | accuracy    0.583\n",
            "| epoch   3 |  4000/ 9649 batches | accuracy    0.585\n",
            "| epoch   3 |  4500/ 9649 batches | accuracy    0.586\n",
            "| epoch   3 |  5000/ 9649 batches | accuracy    0.586\n",
            "| epoch   3 |  5500/ 9649 batches | accuracy    0.582\n",
            "| epoch   3 |  6000/ 9649 batches | accuracy    0.587\n",
            "| epoch   3 |  6500/ 9649 batches | accuracy    0.582\n",
            "| epoch   3 |  7000/ 9649 batches | accuracy    0.585\n",
            "| epoch   3 |  7500/ 9649 batches | accuracy    0.585\n",
            "| epoch   3 |  8000/ 9649 batches | accuracy    0.586\n",
            "| epoch   3 |  8500/ 9649 batches | accuracy    0.585\n",
            "| epoch   3 |  9000/ 9649 batches | accuracy    0.588\n",
            "| epoch   3 |  9500/ 9649 batches | accuracy    0.590\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time: 126.20s | valid accuracy    0.583 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 9649 batches | accuracy    0.590\n",
            "| epoch   4 |  1000/ 9649 batches | accuracy    0.586\n",
            "| epoch   4 |  1500/ 9649 batches | accuracy    0.586\n",
            "| epoch   4 |  2000/ 9649 batches | accuracy    0.591\n",
            "| epoch   4 |  2500/ 9649 batches | accuracy    0.590\n",
            "| epoch   4 |  3000/ 9649 batches | accuracy    0.592\n",
            "| epoch   4 |  3500/ 9649 batches | accuracy    0.590\n",
            "| epoch   4 |  4000/ 9649 batches | accuracy    0.589\n",
            "| epoch   4 |  4500/ 9649 batches | accuracy    0.592\n",
            "| epoch   4 |  5000/ 9649 batches | accuracy    0.590\n",
            "| epoch   4 |  5500/ 9649 batches | accuracy    0.586\n",
            "| epoch   4 |  6000/ 9649 batches | accuracy    0.584\n",
            "| epoch   4 |  6500/ 9649 batches | accuracy    0.596\n",
            "| epoch   4 |  7000/ 9649 batches | accuracy    0.591\n",
            "| epoch   4 |  7500/ 9649 batches | accuracy    0.589\n",
            "| epoch   4 |  8000/ 9649 batches | accuracy    0.595\n",
            "| epoch   4 |  8500/ 9649 batches | accuracy    0.593\n",
            "| epoch   4 |  9000/ 9649 batches | accuracy    0.595\n",
            "| epoch   4 |  9500/ 9649 batches | accuracy    0.594\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time: 126.38s | valid accuracy    0.592 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 9649 batches | accuracy    0.586\n",
            "| epoch   5 |  1000/ 9649 batches | accuracy    0.594\n",
            "| epoch   5 |  1500/ 9649 batches | accuracy    0.595\n",
            "| epoch   5 |  2000/ 9649 batches | accuracy    0.594\n",
            "| epoch   5 |  2500/ 9649 batches | accuracy    0.595\n",
            "| epoch   5 |  3000/ 9649 batches | accuracy    0.593\n",
            "| epoch   5 |  3500/ 9649 batches | accuracy    0.592\n",
            "| epoch   5 |  4000/ 9649 batches | accuracy    0.593\n",
            "| epoch   5 |  4500/ 9649 batches | accuracy    0.593\n",
            "| epoch   5 |  5000/ 9649 batches | accuracy    0.595\n",
            "| epoch   5 |  5500/ 9649 batches | accuracy    0.592\n",
            "| epoch   5 |  6000/ 9649 batches | accuracy    0.595\n",
            "| epoch   5 |  6500/ 9649 batches | accuracy    0.596\n",
            "| epoch   5 |  7000/ 9649 batches | accuracy    0.597\n",
            "| epoch   5 |  7500/ 9649 batches | accuracy    0.593\n",
            "| epoch   5 |  8000/ 9649 batches | accuracy    0.597\n",
            "| epoch   5 |  8500/ 9649 batches | accuracy    0.593\n",
            "| epoch   5 |  9000/ 9649 batches | accuracy    0.595\n",
            "| epoch   5 |  9500/ 9649 batches | accuracy    0.597\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time: 127.97s | valid accuracy    0.588 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 9649 batches | accuracy    0.611\n",
            "| epoch   6 |  1000/ 9649 batches | accuracy    0.611\n",
            "| epoch   6 |  1500/ 9649 batches | accuracy    0.611\n",
            "| epoch   6 |  2000/ 9649 batches | accuracy    0.613\n",
            "| epoch   6 |  2500/ 9649 batches | accuracy    0.615\n",
            "| epoch   6 |  3000/ 9649 batches | accuracy    0.610\n",
            "| epoch   6 |  3500/ 9649 batches | accuracy    0.616\n",
            "| epoch   6 |  4000/ 9649 batches | accuracy    0.610\n",
            "| epoch   6 |  4500/ 9649 batches | accuracy    0.612\n",
            "| epoch   6 |  5000/ 9649 batches | accuracy    0.613\n",
            "| epoch   6 |  5500/ 9649 batches | accuracy    0.613\n",
            "| epoch   6 |  6000/ 9649 batches | accuracy    0.615\n",
            "| epoch   6 |  6500/ 9649 batches | accuracy    0.615\n",
            "| epoch   6 |  7000/ 9649 batches | accuracy    0.611\n",
            "| epoch   6 |  7500/ 9649 batches | accuracy    0.607\n",
            "| epoch   6 |  8000/ 9649 batches | accuracy    0.611\n",
            "| epoch   6 |  8500/ 9649 batches | accuracy    0.610\n",
            "| epoch   6 |  9000/ 9649 batches | accuracy    0.607\n",
            "| epoch   6 |  9500/ 9649 batches | accuracy    0.614\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time: 126.51s | valid accuracy    0.604 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 9649 batches | accuracy    0.611\n",
            "| epoch   7 |  1000/ 9649 batches | accuracy    0.615\n",
            "| epoch   7 |  1500/ 9649 batches | accuracy    0.615\n",
            "| epoch   7 |  2000/ 9649 batches | accuracy    0.614\n",
            "| epoch   7 |  2500/ 9649 batches | accuracy    0.612\n",
            "| epoch   7 |  3000/ 9649 batches | accuracy    0.610\n",
            "| epoch   7 |  3500/ 9649 batches | accuracy    0.617\n",
            "| epoch   7 |  4000/ 9649 batches | accuracy    0.611\n",
            "| epoch   7 |  4500/ 9649 batches | accuracy    0.613\n",
            "| epoch   7 |  5000/ 9649 batches | accuracy    0.613\n",
            "| epoch   7 |  5500/ 9649 batches | accuracy    0.613\n",
            "| epoch   7 |  6000/ 9649 batches | accuracy    0.617\n",
            "| epoch   7 |  6500/ 9649 batches | accuracy    0.609\n",
            "| epoch   7 |  7000/ 9649 batches | accuracy    0.616\n",
            "| epoch   7 |  7500/ 9649 batches | accuracy    0.617\n",
            "| epoch   7 |  8000/ 9649 batches | accuracy    0.618\n",
            "| epoch   7 |  8500/ 9649 batches | accuracy    0.611\n",
            "| epoch   7 |  9000/ 9649 batches | accuracy    0.612\n",
            "| epoch   7 |  9500/ 9649 batches | accuracy    0.616\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time: 125.25s | valid accuracy    0.605 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 9649 batches | accuracy    0.616\n",
            "| epoch   8 |  1000/ 9649 batches | accuracy    0.619\n",
            "| epoch   8 |  1500/ 9649 batches | accuracy    0.617\n",
            "| epoch   8 |  2000/ 9649 batches | accuracy    0.614\n",
            "| epoch   8 |  2500/ 9649 batches | accuracy    0.613\n",
            "| epoch   8 |  3000/ 9649 batches | accuracy    0.611\n",
            "| epoch   8 |  3500/ 9649 batches | accuracy    0.609\n",
            "| epoch   8 |  4000/ 9649 batches | accuracy    0.614\n",
            "| epoch   8 |  4500/ 9649 batches | accuracy    0.610\n",
            "| epoch   8 |  5000/ 9649 batches | accuracy    0.614\n",
            "| epoch   8 |  5500/ 9649 batches | accuracy    0.612\n",
            "| epoch   8 |  6000/ 9649 batches | accuracy    0.613\n",
            "| epoch   8 |  6500/ 9649 batches | accuracy    0.620\n",
            "| epoch   8 |  7000/ 9649 batches | accuracy    0.618\n",
            "| epoch   8 |  7500/ 9649 batches | accuracy    0.615\n",
            "| epoch   8 |  8000/ 9649 batches | accuracy    0.614\n",
            "| epoch   8 |  8500/ 9649 batches | accuracy    0.612\n",
            "| epoch   8 |  9000/ 9649 batches | accuracy    0.610\n",
            "| epoch   8 |  9500/ 9649 batches | accuracy    0.615\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time: 125.90s | valid accuracy    0.604 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 9649 batches | accuracy    0.617\n",
            "| epoch   9 |  1000/ 9649 batches | accuracy    0.614\n",
            "| epoch   9 |  1500/ 9649 batches | accuracy    0.624\n",
            "| epoch   9 |  2000/ 9649 batches | accuracy    0.617\n",
            "| epoch   9 |  2500/ 9649 batches | accuracy    0.621\n",
            "| epoch   9 |  3000/ 9649 batches | accuracy    0.617\n",
            "| epoch   9 |  3500/ 9649 batches | accuracy    0.617\n",
            "| epoch   9 |  4000/ 9649 batches | accuracy    0.614\n",
            "| epoch   9 |  4500/ 9649 batches | accuracy    0.611\n",
            "| epoch   9 |  5000/ 9649 batches | accuracy    0.612\n",
            "| epoch   9 |  5500/ 9649 batches | accuracy    0.613\n",
            "| epoch   9 |  6000/ 9649 batches | accuracy    0.617\n",
            "| epoch   9 |  6500/ 9649 batches | accuracy    0.617\n",
            "| epoch   9 |  7000/ 9649 batches | accuracy    0.615\n",
            "| epoch   9 |  7500/ 9649 batches | accuracy    0.613\n",
            "| epoch   9 |  8000/ 9649 batches | accuracy    0.616\n",
            "| epoch   9 |  8500/ 9649 batches | accuracy    0.616\n",
            "| epoch   9 |  9000/ 9649 batches | accuracy    0.615\n",
            "| epoch   9 |  9500/ 9649 batches | accuracy    0.613\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time: 123.01s | valid accuracy    0.606 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |   500/ 9649 batches | accuracy    0.613\n",
            "| epoch  10 |  1000/ 9649 batches | accuracy    0.618\n",
            "| epoch  10 |  1500/ 9649 batches | accuracy    0.616\n",
            "| epoch  10 |  2000/ 9649 batches | accuracy    0.611\n",
            "| epoch  10 |  2500/ 9649 batches | accuracy    0.618\n",
            "| epoch  10 |  3000/ 9649 batches | accuracy    0.613\n",
            "| epoch  10 |  3500/ 9649 batches | accuracy    0.617\n",
            "| epoch  10 |  4000/ 9649 batches | accuracy    0.612\n",
            "| epoch  10 |  4500/ 9649 batches | accuracy    0.621\n",
            "| epoch  10 |  5000/ 9649 batches | accuracy    0.615\n",
            "| epoch  10 |  5500/ 9649 batches | accuracy    0.620\n",
            "| epoch  10 |  6000/ 9649 batches | accuracy    0.614\n",
            "| epoch  10 |  6500/ 9649 batches | accuracy    0.616\n",
            "| epoch  10 |  7000/ 9649 batches | accuracy    0.617\n",
            "| epoch  10 |  7500/ 9649 batches | accuracy    0.614\n",
            "| epoch  10 |  8000/ 9649 batches | accuracy    0.622\n",
            "| epoch  10 |  8500/ 9649 batches | accuracy    0.615\n",
            "| epoch  10 |  9000/ 9649 batches | accuracy    0.617\n",
            "| epoch  10 |  9500/ 9649 batches | accuracy    0.617\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time: 124.48s | valid accuracy    0.606 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUrnPMhVBlq9",
        "outputId": "a7c23e2f-bdeb-468b-d8e5-1ebd777cab23"
      },
      "source": [
        "print('Checking the results of test dataset.')\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print('test accuracy {:8.3f}'.format(accu_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking the results of test dataset.\n",
            "test accuracy    0.603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur3oRFozl8YF"
      },
      "source": [
        "YelpReviewPolarity?"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VRm8pEPl8V9",
        "outputId": "d4b4a02c-e0de-493a-e3fa-1963386cf7c3"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_iter = YelpReviewPolarity(split = 'train')\n",
        "test_iter = YelpReviewPolarity(split = 'test')\n",
        "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False)\n",
        "# next(iter(dataloader))\n",
        "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)\n",
        "\n",
        "num_class = len(set([label for (label, text) in train_iter]))\n",
        "vocab_size = len(vocab)\n",
        "emsize = 64\n",
        "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 166M/166M [00:02<00:00, 73.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAZRKl9Vl8Tz",
        "outputId": "2d29ffab-914d-4358-a1a9-425fd83b6d59"
      },
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "# Hyperparameters\n",
        "EPOCHS = 10 # epoch\n",
        "LR = 5  # learning rate\n",
        "BATCH_SIZE = 64 # batch size for training\n",
        "  \n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "train_iter, test_iter = YelpReviewPolarity()\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "split_train_, split_valid_ = \\\n",
        "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
        "\n",
        "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
        "                             shuffle=True, collate_fn=collate_batch)\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_dataloader)\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_val\n",
        "    print('-' * 59)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
        "          'valid accuracy {:8.3f} '.format(epoch,\n",
        "                                           time.time() - epoch_start_time,\n",
        "                                           accu_val))\n",
        "    print('-' * 59)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 8313 batches | accuracy    0.776\n",
            "| epoch   1 |  1000/ 8313 batches | accuracy    0.870\n",
            "| epoch   1 |  1500/ 8313 batches | accuracy    0.889\n",
            "| epoch   1 |  2000/ 8313 batches | accuracy    0.895\n",
            "| epoch   1 |  2500/ 8313 batches | accuracy    0.900\n",
            "| epoch   1 |  3000/ 8313 batches | accuracy    0.905\n",
            "| epoch   1 |  3500/ 8313 batches | accuracy    0.907\n",
            "| epoch   1 |  4000/ 8313 batches | accuracy    0.909\n",
            "| epoch   1 |  4500/ 8313 batches | accuracy    0.907\n",
            "| epoch   1 |  5000/ 8313 batches | accuracy    0.913\n",
            "| epoch   1 |  5500/ 8313 batches | accuracy    0.911\n",
            "| epoch   1 |  6000/ 8313 batches | accuracy    0.911\n",
            "| epoch   1 |  6500/ 8313 batches | accuracy    0.911\n",
            "| epoch   1 |  7000/ 8313 batches | accuracy    0.913\n",
            "| epoch   1 |  7500/ 8313 batches | accuracy    0.915\n",
            "| epoch   1 |  8000/ 8313 batches | accuracy    0.915\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   1 | time: 106.27s | valid accuracy    0.924 \n",
            "-----------------------------------------------------------\n",
            "| epoch   2 |   500/ 8313 batches | accuracy    0.919\n",
            "| epoch   2 |  1000/ 8313 batches | accuracy    0.918\n",
            "| epoch   2 |  1500/ 8313 batches | accuracy    0.920\n",
            "| epoch   2 |  2000/ 8313 batches | accuracy    0.921\n",
            "| epoch   2 |  2500/ 8313 batches | accuracy    0.918\n",
            "| epoch   2 |  3000/ 8313 batches | accuracy    0.922\n",
            "| epoch   2 |  3500/ 8313 batches | accuracy    0.923\n",
            "| epoch   2 |  4000/ 8313 batches | accuracy    0.920\n",
            "| epoch   2 |  4500/ 8313 batches | accuracy    0.920\n",
            "| epoch   2 |  5000/ 8313 batches | accuracy    0.921\n",
            "| epoch   2 |  5500/ 8313 batches | accuracy    0.923\n",
            "| epoch   2 |  6000/ 8313 batches | accuracy    0.925\n",
            "| epoch   2 |  6500/ 8313 batches | accuracy    0.924\n",
            "| epoch   2 |  7000/ 8313 batches | accuracy    0.922\n",
            "| epoch   2 |  7500/ 8313 batches | accuracy    0.923\n",
            "| epoch   2 |  8000/ 8313 batches | accuracy    0.920\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   2 | time: 112.80s | valid accuracy    0.924 \n",
            "-----------------------------------------------------------\n",
            "| epoch   3 |   500/ 8313 batches | accuracy    0.925\n",
            "| epoch   3 |  1000/ 8313 batches | accuracy    0.924\n",
            "| epoch   3 |  1500/ 8313 batches | accuracy    0.925\n",
            "| epoch   3 |  2000/ 8313 batches | accuracy    0.925\n",
            "| epoch   3 |  2500/ 8313 batches | accuracy    0.927\n",
            "| epoch   3 |  3000/ 8313 batches | accuracy    0.927\n",
            "| epoch   3 |  3500/ 8313 batches | accuracy    0.927\n",
            "| epoch   3 |  4000/ 8313 batches | accuracy    0.922\n",
            "| epoch   3 |  4500/ 8313 batches | accuracy    0.925\n",
            "| epoch   3 |  5000/ 8313 batches | accuracy    0.928\n",
            "| epoch   3 |  5500/ 8313 batches | accuracy    0.927\n",
            "| epoch   3 |  6000/ 8313 batches | accuracy    0.926\n",
            "| epoch   3 |  6500/ 8313 batches | accuracy    0.929\n",
            "| epoch   3 |  7000/ 8313 batches | accuracy    0.930\n",
            "| epoch   3 |  7500/ 8313 batches | accuracy    0.927\n",
            "| epoch   3 |  8000/ 8313 batches | accuracy    0.931\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   3 | time: 107.87s | valid accuracy    0.934 \n",
            "-----------------------------------------------------------\n",
            "| epoch   4 |   500/ 8313 batches | accuracy    0.931\n",
            "| epoch   4 |  1000/ 8313 batches | accuracy    0.929\n",
            "| epoch   4 |  1500/ 8313 batches | accuracy    0.931\n",
            "| epoch   4 |  2000/ 8313 batches | accuracy    0.929\n",
            "| epoch   4 |  2500/ 8313 batches | accuracy    0.929\n",
            "| epoch   4 |  3000/ 8313 batches | accuracy    0.931\n",
            "| epoch   4 |  3500/ 8313 batches | accuracy    0.928\n",
            "| epoch   4 |  4000/ 8313 batches | accuracy    0.929\n",
            "| epoch   4 |  4500/ 8313 batches | accuracy    0.930\n",
            "| epoch   4 |  5000/ 8313 batches | accuracy    0.929\n",
            "| epoch   4 |  5500/ 8313 batches | accuracy    0.927\n",
            "| epoch   4 |  6000/ 8313 batches | accuracy    0.929\n",
            "| epoch   4 |  6500/ 8313 batches | accuracy    0.930\n",
            "| epoch   4 |  7000/ 8313 batches | accuracy    0.929\n",
            "| epoch   4 |  7500/ 8313 batches | accuracy    0.928\n",
            "| epoch   4 |  8000/ 8313 batches | accuracy    0.930\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   4 | time: 111.09s | valid accuracy    0.934 \n",
            "-----------------------------------------------------------\n",
            "| epoch   5 |   500/ 8313 batches | accuracy    0.931\n",
            "| epoch   5 |  1000/ 8313 batches | accuracy    0.932\n",
            "| epoch   5 |  1500/ 8313 batches | accuracy    0.930\n",
            "| epoch   5 |  2000/ 8313 batches | accuracy    0.931\n",
            "| epoch   5 |  2500/ 8313 batches | accuracy    0.933\n",
            "| epoch   5 |  3000/ 8313 batches | accuracy    0.931\n",
            "| epoch   5 |  3500/ 8313 batches | accuracy    0.930\n",
            "| epoch   5 |  4000/ 8313 batches | accuracy    0.928\n",
            "| epoch   5 |  4500/ 8313 batches | accuracy    0.930\n",
            "| epoch   5 |  5000/ 8313 batches | accuracy    0.931\n",
            "| epoch   5 |  5500/ 8313 batches | accuracy    0.933\n",
            "| epoch   5 |  6000/ 8313 batches | accuracy    0.932\n",
            "| epoch   5 |  6500/ 8313 batches | accuracy    0.932\n",
            "| epoch   5 |  7000/ 8313 batches | accuracy    0.933\n",
            "| epoch   5 |  7500/ 8313 batches | accuracy    0.929\n",
            "| epoch   5 |  8000/ 8313 batches | accuracy    0.932\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   5 | time: 110.25s | valid accuracy    0.873 \n",
            "-----------------------------------------------------------\n",
            "| epoch   6 |   500/ 8313 batches | accuracy    0.941\n",
            "| epoch   6 |  1000/ 8313 batches | accuracy    0.941\n",
            "| epoch   6 |  1500/ 8313 batches | accuracy    0.939\n",
            "| epoch   6 |  2000/ 8313 batches | accuracy    0.943\n",
            "| epoch   6 |  2500/ 8313 batches | accuracy    0.942\n",
            "| epoch   6 |  3000/ 8313 batches | accuracy    0.938\n",
            "| epoch   6 |  3500/ 8313 batches | accuracy    0.942\n",
            "| epoch   6 |  4000/ 8313 batches | accuracy    0.941\n",
            "| epoch   6 |  4500/ 8313 batches | accuracy    0.941\n",
            "| epoch   6 |  5000/ 8313 batches | accuracy    0.942\n",
            "| epoch   6 |  5500/ 8313 batches | accuracy    0.943\n",
            "| epoch   6 |  6000/ 8313 batches | accuracy    0.941\n",
            "| epoch   6 |  6500/ 8313 batches | accuracy    0.941\n",
            "| epoch   6 |  7000/ 8313 batches | accuracy    0.941\n",
            "| epoch   6 |  7500/ 8313 batches | accuracy    0.943\n",
            "| epoch   6 |  8000/ 8313 batches | accuracy    0.939\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   6 | time: 107.56s | valid accuracy    0.938 \n",
            "-----------------------------------------------------------\n",
            "| epoch   7 |   500/ 8313 batches | accuracy    0.943\n",
            "| epoch   7 |  1000/ 8313 batches | accuracy    0.942\n",
            "| epoch   7 |  1500/ 8313 batches | accuracy    0.941\n",
            "| epoch   7 |  2000/ 8313 batches | accuracy    0.941\n",
            "| epoch   7 |  2500/ 8313 batches | accuracy    0.941\n",
            "| epoch   7 |  3000/ 8313 batches | accuracy    0.943\n",
            "| epoch   7 |  3500/ 8313 batches | accuracy    0.943\n",
            "| epoch   7 |  4000/ 8313 batches | accuracy    0.942\n",
            "| epoch   7 |  4500/ 8313 batches | accuracy    0.941\n",
            "| epoch   7 |  5000/ 8313 batches | accuracy    0.944\n",
            "| epoch   7 |  5500/ 8313 batches | accuracy    0.942\n",
            "| epoch   7 |  6000/ 8313 batches | accuracy    0.943\n",
            "| epoch   7 |  6500/ 8313 batches | accuracy    0.940\n",
            "| epoch   7 |  7000/ 8313 batches | accuracy    0.939\n",
            "| epoch   7 |  7500/ 8313 batches | accuracy    0.942\n",
            "| epoch   7 |  8000/ 8313 batches | accuracy    0.942\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   7 | time: 108.48s | valid accuracy    0.938 \n",
            "-----------------------------------------------------------\n",
            "| epoch   8 |   500/ 8313 batches | accuracy    0.942\n",
            "| epoch   8 |  1000/ 8313 batches | accuracy    0.943\n",
            "| epoch   8 |  1500/ 8313 batches | accuracy    0.941\n",
            "| epoch   8 |  2000/ 8313 batches | accuracy    0.945\n",
            "| epoch   8 |  2500/ 8313 batches | accuracy    0.944\n",
            "| epoch   8 |  3000/ 8313 batches | accuracy    0.941\n",
            "| epoch   8 |  3500/ 8313 batches | accuracy    0.942\n",
            "| epoch   8 |  4000/ 8313 batches | accuracy    0.942\n",
            "| epoch   8 |  4500/ 8313 batches | accuracy    0.939\n",
            "| epoch   8 |  5000/ 8313 batches | accuracy    0.943\n",
            "| epoch   8 |  5500/ 8313 batches | accuracy    0.944\n",
            "| epoch   8 |  6000/ 8313 batches | accuracy    0.944\n",
            "| epoch   8 |  6500/ 8313 batches | accuracy    0.943\n",
            "| epoch   8 |  7000/ 8313 batches | accuracy    0.943\n",
            "| epoch   8 |  7500/ 8313 batches | accuracy    0.942\n",
            "| epoch   8 |  8000/ 8313 batches | accuracy    0.941\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   8 | time: 107.65s | valid accuracy    0.939 \n",
            "-----------------------------------------------------------\n",
            "| epoch   9 |   500/ 8313 batches | accuracy    0.941\n",
            "| epoch   9 |  1000/ 8313 batches | accuracy    0.943\n",
            "| epoch   9 |  1500/ 8313 batches | accuracy    0.943\n",
            "| epoch   9 |  2000/ 8313 batches | accuracy    0.943\n",
            "| epoch   9 |  2500/ 8313 batches | accuracy    0.941\n",
            "| epoch   9 |  3000/ 8313 batches | accuracy    0.943\n",
            "| epoch   9 |  3500/ 8313 batches | accuracy    0.941\n",
            "| epoch   9 |  4000/ 8313 batches | accuracy    0.944\n",
            "| epoch   9 |  4500/ 8313 batches | accuracy    0.943\n",
            "| epoch   9 |  5000/ 8313 batches | accuracy    0.944\n",
            "| epoch   9 |  5500/ 8313 batches | accuracy    0.942\n",
            "| epoch   9 |  6000/ 8313 batches | accuracy    0.946\n",
            "| epoch   9 |  6500/ 8313 batches | accuracy    0.940\n",
            "| epoch   9 |  7000/ 8313 batches | accuracy    0.941\n",
            "| epoch   9 |  7500/ 8313 batches | accuracy    0.942\n",
            "| epoch   9 |  8000/ 8313 batches | accuracy    0.943\n",
            "-----------------------------------------------------------\n",
            "| end of epoch   9 | time: 109.30s | valid accuracy    0.939 \n",
            "-----------------------------------------------------------\n",
            "| epoch  10 |   500/ 8313 batches | accuracy    0.942\n",
            "| epoch  10 |  1000/ 8313 batches | accuracy    0.942\n",
            "| epoch  10 |  1500/ 8313 batches | accuracy    0.942\n",
            "| epoch  10 |  2000/ 8313 batches | accuracy    0.944\n",
            "| epoch  10 |  2500/ 8313 batches | accuracy    0.943\n",
            "| epoch  10 |  3000/ 8313 batches | accuracy    0.942\n",
            "| epoch  10 |  3500/ 8313 batches | accuracy    0.943\n",
            "| epoch  10 |  4000/ 8313 batches | accuracy    0.944\n",
            "| epoch  10 |  4500/ 8313 batches | accuracy    0.943\n",
            "| epoch  10 |  5000/ 8313 batches | accuracy    0.943\n",
            "| epoch  10 |  5500/ 8313 batches | accuracy    0.945\n",
            "| epoch  10 |  6000/ 8313 batches | accuracy    0.943\n",
            "| epoch  10 |  6500/ 8313 batches | accuracy    0.944\n",
            "| epoch  10 |  7000/ 8313 batches | accuracy    0.943\n",
            "| epoch  10 |  7500/ 8313 batches | accuracy    0.945\n",
            "| epoch  10 |  8000/ 8313 batches | accuracy    0.943\n",
            "-----------------------------------------------------------\n",
            "| end of epoch  10 | time: 109.07s | valid accuracy    0.939 \n",
            "-----------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOTAc_Djl8Rp",
        "outputId": "b362f638-c8de-4839-91c9-2a2c5651aeca"
      },
      "source": [
        "print('Checking the results of test dataset.')\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print('test accuracy {:8.3f}'.format(accu_test))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking the results of test dataset.\n",
            "test accuracy    0.941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc9z4iNTl8PN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fjz5A6MVl8M1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dwbZkXul8Kd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBk6lyFTl8H_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76PGhuKbB4BN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a579c477-77b9-4aa9-d90b-abd45e6d28ff"
      },
      "source": [
        "# ag_news_label = {1: \"World\",\n",
        "#                  2: \"Sports\",\n",
        "#                  3: \"Business\",\n",
        "#                  4: \"Sci/Tec\"}\n",
        "\n",
        "# def predict(text, text_pipeline):\n",
        "#     with torch.no_grad():\n",
        "#         text = torch.tensor(text_pipeline(text))\n",
        "#         output = model(text, torch.tensor([0]))\n",
        "#         return output.argmax(1).item() + 1\n",
        "\n",
        "# ex_text_str = \"MEMPHIS, Tenn. – Four days ago, Jon Rahm was \\\n",
        "#     enduring the season’s worst weather conditions on Sunday at The \\\n",
        "#     Open on his way to a closing 75 at Royal Portrush, which \\\n",
        "#     considering the wind and the rain was a respectable showing. \\\n",
        "#     Thursday’s first round at the WGC-FedEx St. Jude Invitational \\\n",
        "#     was another story. With temperatures in the mid-80s and hardly any \\\n",
        "#     wind, the Spaniard was 13 strokes better in a flawless round. \\\n",
        "#     Thanks to his best putting performance on the PGA Tour, Rahm \\\n",
        "#     finished with an 8-under 62 for a three-stroke lead, which \\\n",
        "#     was even more impressive considering he’d never played the \\\n",
        "#     front nine at TPC Southwind.\"\n",
        "\n",
        "# model = model.to(\"cpu\")\n",
        "\n",
        "# print(\"This is a %s news\" %ag_news_label[predict(ex_text_str, text_pipeline)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a Sports news\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-bXp1P9B55k"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}